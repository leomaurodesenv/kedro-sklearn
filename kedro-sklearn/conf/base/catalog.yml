# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

_csv: &csv
  type: pandas.CSVDataSet
  load_args:
    sep: ','

_joblib: &joblib
  type: pickle.PickleDataSet
  backend: joblib

_pickle: &pickle
  type: pickle.PickleDataSet
  backend: pickle

_json: &json
  type: json.JSONDataSet

## Dataset
train:
  <<: *csv
  filepath: data/01_raw/train.csv

test:
  <<: *csv
  filepath: data/01_raw/test.csv

sample_submission:
  <<: *csv
  filepath: data/01_raw/sample_submission.csv

## Preprocessing
train_X:
  <<: *pickle
  filepath: data/05_model_input/train_X.pkl

train_y:
  <<: *pickle
  filepath: data/05_model_input/train_y.pkl

test_X:
  <<: *pickle
  filepath: data/05_model_input/test_X.pkl

## Features
feature_vectorizer:
  <<: *joblib
  filepath: data/04_feature/vectorizer.joblib

## Models
model_svc:
  <<: *joblib
  filepath: data/06_models/model-svc.joblib

model_random_forest:
  <<: *joblib
  filepath: data/06_models/model-random_forest.joblib

model_logistic_regression:
  <<: *joblib
  filepath: data/06_models/model-logistic_regression.joblib

metrics_svc:
  <<: *json
  filepath: data/06_models/metrics-svc.json

metrics_random_forest:
  <<: *json
  filepath: data/06_models/metrics-random_forest.json

metrics_logistic_regression:
  <<: *json
  filepath: data/06_models/metrics-logistic_regression.json

## Selection
f1.selected_model:
  <<: *joblib
  filepath: data/06_models/f1.selected_model.joblib
  versioned: true

f1.submission:
  <<: *csv
  filepath: data/07_model_output/f1.submission.csv

accuracy.selected_model:
  <<: *joblib
  filepath: data/06_models/accuracy.selected_model.joblib
  versioned: true

accuracy.submission:
  <<: *csv
  filepath: data/07_model_output/accuracy.submission.csv
